"""
üöÄ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Open Interpreter ‡∏Å‡∏±‡∏ö Ollama
==================================================

## ‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!

Ollama models ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:

- llama3.2:latest (2.0 GB) ‚≠ê ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
- qwen2.5:latest (4.7 GB)
- phi3:latest (2.2 GB)
- codestral:22b (12 GB) - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
- deepseek-coder:33b (18 GB) - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î

## üîß ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### 1. Terminal Command:

```bash
interpreter --model ollama/llama3.2:latest --api-base http://localhost:11434
```

### 2. Python Script:

```python
from interpreter import interpreter

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Ollama
interpreter.llm.model = "ollama/llama3.2:latest"
interpreter.llm.api_base = "http://localhost:11434"
interpreter.auto_run = True
interpreter.offline = True

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
interpreter.chat("‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå hello.py")
```

### 3. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Model:

```python
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
interpreter.llm.model = "ollama/codestral:22b"

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡πÄ‡∏£‡πá‡∏ß)
interpreter.llm.model = "ollama/phi3:latest"

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
interpreter.llm.model = "ollama/qwen2.5:latest"
```

## üéØ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°:

```
"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏•‡∏Ç‡∏ü‡∏µ‡πÇ‡∏ö‡∏ô‡∏±‡∏Å‡∏ä‡∏µ"
"‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå HTML ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"
"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡∏° Guess Number ‡∏î‡πâ‡∏ß‡∏¢ Python"
```

### ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå:

```
"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå CSV ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"
"‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå .txt ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"
"‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON ‡πÄ‡∏õ‡πá‡∏ô Excel"
```

### ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:

```
"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç"
"‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå CSV ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"
"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô PDF ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
```

## üõ†Ô∏è ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Connection Error

```bash
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏£‡∏¥‡πà‡∏° Ollama server
ollama serve
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Model ‡πÑ‡∏°‡πà‡∏°‡∏µ

```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡πÉ‡∏´‡∏°‡πà
ollama pull llama3.2:latest
ollama pull codestral:22b
```

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏ä‡πâ‡∏≤

```python
# ‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
interpreter.llm.model = "ollama/phi3:latest"
```

## ‚ö° Tips ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

1. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Model ‡∏ï‡∏≤‡∏°‡∏á‡∏≤‡∏ô:**

   - ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ: phi3:latest, llama3.2:latest
   - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î: codestral:22b, deepseek-coder:33b
   - ‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å: qwen2.5:latest

2. **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î RAM:**

   - ‡πÉ‡∏ä‡πâ model ‡πÄ‡∏•‡πá‡∏Å (phi3, llama3.2)
   - ‡∏õ‡∏¥‡∏î model ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ: `ollama stop model_name`

3. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß:**
   ```python
   interpreter.llm.temperature = 0.1  # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡πà‡∏°
   interpreter.llm.max_tokens = 1000  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î output
   ```

## üé™ Demo Scripts ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ

1. **simple_ollama_test.py** - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
2. **ollama_demo.py** - Demo ‡∏Ñ‡∏£‡∏ö‡∏Ñ‡∏£‡∏±‡∏ô
3. **test_oi_demo.py** - Demo ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡∏≠‡∏ö)

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```bash
python simple_runner.py
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏£‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô

```bash
python simple_ollama_test.py
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏£‡∏±‡∏ô Demo ‡∏Ñ‡∏£‡∏ö‡∏Ñ‡∏£‡∏±‡∏ô

```bash
python ollama_demo.py
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 4: ‡∏£‡∏±‡∏ô‡∏á‡∏≤‡∏ô‡∏î‡πà‡∏ß‡∏ô

```bash
python quick_runner.py
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 5: ‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Command Line

```bash
python -c "from interpreter import interpreter; interpreter.llm.model='ollama/llama3.2:latest'; interpreter.llm.api_base='http://localhost:11434'; interpreter.auto_run=True; interpreter.chat()"
```

## üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå:

- "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå hello.txt"
- "‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"
- "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì 1+1"
- "‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"

üéâ **‡∏Ñ‡∏∏‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Open Interpreter ‡∏Å‡∏±‡∏ö Ollama ‡πÅ‡∏•‡πâ‡∏ß!**
"""
